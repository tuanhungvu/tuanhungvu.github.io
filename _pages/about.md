---
permalink: /
title: "About"
excerpt: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Tuan-Hung Vu is a research scientist at [valeo.ai](https://www.valeo.com/en/valeo-ai/), France (2018-now). He received his PhD from [École Normale Supérieure](http://www.ens.fr/en), under the supervision of [Ivan Laptev](https://www.di.ens.fr/~laptev). Tuan-Hung obtained an engineering degree from [Télécom Paris](https://en.wikipedia.org/wiki/T%C3%A9l%C3%A9com_Paris) and a parallel “Master 2” degree in Mathematics, Machine Learning and Computer Vision ([MVA](http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/)) from [École Normale Supérieure Paris-Saclay](https://ens-paris-saclay.fr/en) in 2014. His research interests include deep learning, scene understanding, domain adaptation and data augmentation.

## UPDATES
* **NEWS** 11/2022: Top reviewer NeuRIPS'22
* **NEWS** 09/2022: The code of DenseMTL is [released](https://github.com/cv-rits/DenseMTL).
* **NEWS** 08/2022: One accepted WACV [paper](https://arxiv.org/abs/2206.08927).
* **NEWS** 06/2022: Our recent [work](https://arxiv.org/abs/2206.08927) on "Cross-task Attention Mechanism for Dense Multi-task Learning" is online. [Code](https://github.com/cv-rits/DenseMTL) is comming soon.
* **NEWS** 05/2022: We’re organizing a [workshop on Weakly Supervised Computer Vision](https://wscv-indaba.github.io/) at the Deep Learning Indaba 2022.
* **NEWS** 04/2022: Our two papers "CSG0: Continual Urban Scene Generation with Zero Forgetting" and "Multi-Head Distillation for Continual Unsupervised Domain Adaptation in Semantic Segmentation" are accepted to CVPR'20 CLVISION Workshop.
* **NEWS** 01/2022: Our paper "Cross-modal Learning for Domain Adaptation in 3D Semantic Segmentation" is accepted to T-PAMI.

* 11/2021: The [CSG0](https://arxiv.org/abs/2112.03252) preprint of "CSG0: Continual Urban Scene Generation with Zero Forgetting" is online.
* 08/2021: Our [paper](https://arxiv.org/abs/2004.01130) on boundless unsupervised domain adaptation is accepted to CVIU.
* 07/2021: One [paper](https://arxiv.org/abs/2108.06962) about multi-target domain adaptation is accepted to ICCV'2021
* 07/2021: The [Semantic Palette](https://arxiv.org/pdf/2106.01629.pdf) code is [released](https://github.com/valeoai/SemanticPalette).
* 06/2021: The [preprint](https://arxiv.org/pdf/2106.01629.pdf) and [video](https://www.youtube.com/watch?v=ejkbaJD4Emk) of Semantic Palette are available.
* 05/2021: Our work in confidence esimation and its use in improving domain adaptation is accepted to T-PAMI. Updated [paper](https://arxiv.org/abs/2012.06508) is coming soon.
* 05/2021: Outstanding reviewer CVPR'21
* 03/2021: Outstanding reviewer ICLR'21 
* 02/2021: Our paper [Semantic Palette]() on layout-scene generation is accepted to CVPR'2021. Preprint is coming soon.
* 01/2021: The [xMUDA/XMoSSDA]() preprint of "Cross-modal Learning for Domain Adaptation in 3D Semantic Segmentation" is online.
* 01/2021: The [ConDA](https://arxiv.org/abs/2012.06508) preprint of "Confidence Estimation via Auxiliary Models" is online.

* 06/2020: The [xMUDA](https://arxiv.org/abs/1911.12676) code is [released](https://github.com/valeoai/xmuda).
* 05/2020: Our paper [ESL](https://arxiv.org/abs/2006.08658) of using entropy-guided pseudo-labels in UDA is accepted to CVPR 2020 Workshop on [Scalability in Autonomous Driving](https://sites.google.com/view/cvpr20-scalability/posters?authuser=0).
* 04/2020: The [BUDA](https://arxiv.org/abs/2004.01130) preprint of boundless unsupervised domain adaptation is online.
* 02/2020: Our paper [xMUDA](http://arxiv.org/abs/1911.12676) of cross 2D-3D unsupervised domain adaptation is accepted to CVPR'20.
* 01/2020: [Demo at CES](https://www.valeo.com/en/valeo-innovations-at-the-epicenter-of-transformation-in-mobility/), Las Vegas, on pedestrian behavior understanding and forecasting. Press [1](https://www.rtl.fr/actu/futur/ces-2020-la-voiture-autonome-valeo-veut-predire-les-intentions-des-pietons-7799840637), [2](https://bfmbusiness.bfmtv.com/mediaplayer/video/culture-geek-les-voitures-du-futur-sont-au-consumer-electronics-show-0801-1213277.html), [3](https://www.motortrend.com/news/autonomous-car-innovations/), ...

* 12/2019: The [DADA](https://arxiv.org/abs/1904.01886) code is [released](https://github.com/valeoai/DADA).
* 12/2019: The [Zero-shot semantic segmentation](https://arxiv.org/abs/1906.00817) code is [released](https://github.com/valeoai/ZS3).
* 12/2019: The [xMUDA](http://arxiv.org/abs/1911.12676) preprint of cross 2D-3D unsupervised domain adaptation is online. [Demo](https://www.youtube.com/watch?v=WgvBBCEKQVE)
* 09/2019: Our paper [Zero-shot Semantic Segmentation](https://arxiv.org/abs/1906.00817) is accepted to NeurIPS'19.
* 08/2019: Invited talk at BNP Paribas AI Summer School.
* Our paper [DADA](https://arxiv.org/abs/1904.01886) is accepted to ICCV'19.
* The [ADVENT](https://arxiv.org/abs/1811.12833) code is [released](https://github.com/valeoai/ADVENT).
* 06/2019: The [ZS3](https://arxiv.org/abs/1906.00817) preprint of zero-shot semantic segmentation is online.
* 06/2019: *Keynote talk* at [ULAD](http://intelligent-vehicles.org/ulad-2019) - 1st workshop on Unsupervised Learning for Automated Driving - at IV 2019.
* 04/2019: The [DADA](https://arxiv.org/abs/1904.01886) preprint of unsupervised domain adaptation is online.
* 04/2019: Our paper [ADVENT](https://arxiv.org/abs/1811.12833) is accepted to CVPR'19 as an **Oral** presentation.

* 12/2018: The [Tube-CNN](https://arxiv.org/abs/1812.02619) preprint of object detection in videos is online.
* 11/2018: The [ADVENT](https://arxiv.org/abs/1811.12833) preprint of unsupervised domain adaptation is online.
* 09/2018: I successfully defended my PhD!
* 05/2018: Our [MemNet](https://arxiv.org/abs/1803.10861) paper of object detection in videos is accepted to WACV'19.
* From 03/2018 I'll join valeo.ai as a research scientist.

* 06/2017: Internship at NEC Labs, Cupertino in summer 2017.
* 06/2016: [Code](https://github.com/aosokin/cnn_head_detection) for the ICCV'15 paper was released.
* 11/2015: A [paper](https://www.di.ens.fr/willow/research/headdetection/) of human head detection in movies is accepted to ICCV'15.
* 07/2014: [Dataset](https://www.di.ens.fr/willow/research/actionsfromscenes/SUNAction.zip) for the ECCV'14 paper was released.
* 07/2014: A [paper](https://www.di.ens.fr/willow/research/actionsfromscenes) of action prediction is accepted to ECCV'14.